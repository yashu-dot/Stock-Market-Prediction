{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['htz','cvx','bcs','tm','amzn','wmt','googl']\n",
    "df = pd.DataFrame(columns=['Ticker', 'date', 'Time', 'Title']) \n",
    "for ticker in tickers:\n",
    "    url = f'https://finviz.com/quote.ashx?t={ticker}'\n",
    "    req = Request(url=url, headers={'user-agent': 'news'})\n",
    "    response = urlopen(req)\n",
    "    news_tables ={}\n",
    "    html = BeautifulSoup(response, features = 'html.parser')\n",
    "    news_table = html.find(id = 'news-table')\n",
    "    news_tables[ticker] = news_table\n",
    "    ignore_source = ['(Motley Fool)', '(TheStreet.com)']\n",
    "    parsed = []    \n",
    "    for ticker, news_table in news_tables.items():  \n",
    "        for row in news_table.findAll('tr'): \n",
    "            if row.a != None:\n",
    "                title = row.a.text\n",
    "                source = row.span.text\n",
    "                date = row.td.text.strip().split(' ')\n",
    "                if len(date) > 1:    \n",
    "                    date1 = date[0]\n",
    "                    time = date[1]\n",
    "                else:\n",
    "                    time = date[0] \n",
    "            if source.strip() not in ignore_source:\n",
    "                parsed.append([ticker, date1, time, title])  \n",
    "    temp = pd.DataFrame(parsed, columns=['Ticker', 'date', 'Time', 'Title']) \n",
    "    df = pd.concat([df,temp],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = SentimentIntensityAnalyzer()\n",
    "p_score = lambda title: vader.polarity_scores(title)['pos']\n",
    "n_score = lambda title: vader.polarity_scores(title)['neu']\n",
    "neg_score = lambda title: vader.polarity_scores(title)['neg']\n",
    "score = lambda title: vader.polarity_scores(title)['compound']\n",
    "df['postive'] = df['Title'].apply(p_score) \n",
    "df['negative'] = df['Title'].apply(neg_score) \n",
    "df['neutral'] = df['Title'].apply(n_score) \n",
    "df['compound'] = df['Title'].apply(score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Title</th>\n",
       "      <th>postive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>htz</td>\n",
       "      <td>Nov-30-23</td>\n",
       "      <td>10:35AM</td>\n",
       "      <td>Hertz and Carvana: what their diverging fortun...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>htz</td>\n",
       "      <td>Nov-17-23</td>\n",
       "      <td>07:00AM</td>\n",
       "      <td>Hertz and EVgo Partner to Offer EV Renters One...</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>htz</td>\n",
       "      <td>Nov-07-23</td>\n",
       "      <td>03:12PM</td>\n",
       "      <td>WeBroke: Investors Must Avoid WE Stock if It T...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.804</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>htz</td>\n",
       "      <td>Oct-30-23</td>\n",
       "      <td>01:57AM</td>\n",
       "      <td>The Hertz Global Holdings Inc (HTZ) Company: A...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>htz</td>\n",
       "      <td>Oct-28-23</td>\n",
       "      <td>03:52PM</td>\n",
       "      <td>Hertz Global Holdings, Inc. (NASDAQ:HTZ) Q3 20...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>googl</td>\n",
       "      <td>Nov-27-23</td>\n",
       "      <td>01:59PM</td>\n",
       "      <td>Jeff Bezos Was An Early Investor In Google  A ...</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.7096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>googl</td>\n",
       "      <td>Nov-27-23</td>\n",
       "      <td>01:19PM</td>\n",
       "      <td>Google will start deleting 'inactive' accounts...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>googl</td>\n",
       "      <td>Nov-27-23</td>\n",
       "      <td>01:16PM</td>\n",
       "      <td>The World's Most Profitable Company Is Not App...</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.4927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>googl</td>\n",
       "      <td>Nov-27-23</td>\n",
       "      <td>01:06PM</td>\n",
       "      <td>Warren Buffett Stocks: Google Among 27 Names O...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>googl</td>\n",
       "      <td>Nov-27-23</td>\n",
       "      <td>12:19PM</td>\n",
       "      <td>Google to begin deleting inactive accounts thi...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker       date     Time  \\\n",
       "0     htz  Nov-30-23  10:35AM   \n",
       "1     htz  Nov-17-23  07:00AM   \n",
       "2     htz  Nov-07-23  03:12PM   \n",
       "3     htz  Oct-30-23  01:57AM   \n",
       "4     htz  Oct-28-23  03:52PM   \n",
       "..    ...        ...      ...   \n",
       "69  googl  Nov-27-23  01:59PM   \n",
       "70  googl  Nov-27-23  01:19PM   \n",
       "71  googl  Nov-27-23  01:16PM   \n",
       "72  googl  Nov-27-23  01:06PM   \n",
       "73  googl  Nov-27-23  12:19PM   \n",
       "\n",
       "                                                Title  postive  negative  \\\n",
       "0   Hertz and Carvana: what their diverging fortun...    0.000     0.000   \n",
       "1   Hertz and EVgo Partner to Offer EV Renters One...    0.172     0.000   \n",
       "2   WeBroke: Investors Must Avoid WE Stock if It T...    0.000     0.196   \n",
       "3   The Hertz Global Holdings Inc (HTZ) Company: A...    0.000     0.000   \n",
       "4   Hertz Global Holdings, Inc. (NASDAQ:HTZ) Q3 20...    0.000     0.000   \n",
       "..                                                ...      ...       ...   \n",
       "69  Jeff Bezos Was An Early Investor In Google  A ...    0.148     0.000   \n",
       "70  Google will start deleting 'inactive' accounts...    0.000     0.000   \n",
       "71  The World's Most Profitable Company Is Not App...    0.166     0.000   \n",
       "72  Warren Buffett Stocks: Google Among 27 Names O...    0.000     0.000   \n",
       "73  Google to begin deleting inactive accounts thi...    0.000     0.000   \n",
       "\n",
       "    neutral  compound  \n",
       "0     1.000    0.0000  \n",
       "1     0.828    0.4019  \n",
       "2     0.804   -0.2960  \n",
       "3     1.000    0.0000  \n",
       "4     1.000    0.0000  \n",
       "..      ...       ...  \n",
       "69    0.852    0.7096  \n",
       "70    1.000    0.0000  \n",
       "71    0.834    0.4927  \n",
       "72    1.000    0.0000  \n",
       "73    1.000    0.0000  \n",
       "\n",
       "[586 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'] = df['date'].replace('Today','Dec-03-23')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/l4spbz4s3rvdh8g0ch7_7zsc0000gn/T/ipykernel_4715/16268215.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df.date).dt.date\n"
     ]
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df.date).dt.date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>Title</th>\n",
       "      <th>postive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>htz</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>Hertz and Carvana: what their diverging fortun...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>htz</td>\n",
       "      <td>2023-11-17</td>\n",
       "      <td>Hertz and EVgo Partner to Offer EV Renters One...</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>htz</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>WeBroke: Investors Must Avoid WE Stock if It T...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.804</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>htz</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>The Hertz Global Holdings Inc (HTZ) Company: A...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>htz</td>\n",
       "      <td>2023-10-28</td>\n",
       "      <td>Hertz Global Holdings, Inc. (NASDAQ:HTZ) Q3 20...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>googl</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>Jeff Bezos Was An Early Investor In Google  A ...</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.7096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>googl</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>Google will start deleting 'inactive' accounts...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>googl</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>The World's Most Profitable Company Is Not App...</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.4927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>googl</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>Warren Buffett Stocks: Google Among 27 Names O...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>googl</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>Google to begin deleting inactive accounts thi...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker        date                                              Title  \\\n",
       "0     htz  2023-11-30  Hertz and Carvana: what their diverging fortun...   \n",
       "1     htz  2023-11-17  Hertz and EVgo Partner to Offer EV Renters One...   \n",
       "2     htz  2023-11-07  WeBroke: Investors Must Avoid WE Stock if It T...   \n",
       "3     htz  2023-10-30  The Hertz Global Holdings Inc (HTZ) Company: A...   \n",
       "4     htz  2023-10-28  Hertz Global Holdings, Inc. (NASDAQ:HTZ) Q3 20...   \n",
       "..    ...         ...                                                ...   \n",
       "69  googl  2023-11-27  Jeff Bezos Was An Early Investor In Google  A ...   \n",
       "70  googl  2023-11-27  Google will start deleting 'inactive' accounts...   \n",
       "71  googl  2023-11-27  The World's Most Profitable Company Is Not App...   \n",
       "72  googl  2023-11-27  Warren Buffett Stocks: Google Among 27 Names O...   \n",
       "73  googl  2023-11-27  Google to begin deleting inactive accounts thi...   \n",
       "\n",
       "    postive  negative  neutral  compound  \n",
       "0     0.000     0.000    1.000    0.0000  \n",
       "1     0.172     0.000    0.828    0.4019  \n",
       "2     0.000     0.196    0.804   -0.2960  \n",
       "3     0.000     0.000    1.000    0.0000  \n",
       "4     0.000     0.000    1.000    0.0000  \n",
       "..      ...       ...      ...       ...  \n",
       "69    0.148     0.000    0.852    0.7096  \n",
       "70    0.000     0.000    1.000    0.0000  \n",
       "71    0.166     0.000    0.834    0.4927  \n",
       "72    0.000     0.000    1.000    0.0000  \n",
       "73    0.000     0.000    1.000    0.0000  \n",
       "\n",
       "[586 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Time'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of missing dates are:  908\n"
     ]
    }
   ],
   "source": [
    "amzn = pd.read_csv('AMZN.csv')\n",
    "amzn['Ticker'] = 'amzn'\n",
    "data = amzn\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data=data.sort_values(by=\"Date\",ascending=True)\n",
    "data.set_index(\"Date\",inplace=True)\n",
    "start_date = data.index.min()\n",
    "end_date = data.index.max()\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "missing_dates = all_dates.difference(data.index)\n",
    "print(\"The count of missing dates are: \",len(missing_dates))\n",
    "data = data.reindex(all_dates)\n",
    "data.ffill(inplace=True)\n",
    "data['Difference'] = data['Adj Close'].diff()\n",
    "data = data.dropna()\n",
    "data['Invest'] = 'No'\n",
    "data.loc[data['Difference'] >= 0, 'Invest'] = 'Yes'\n",
    "amzn = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of missing dates are:  112\n"
     ]
    }
   ],
   "source": [
    "bcs = pd.read_csv('BCS.csv')\n",
    "bcs['Ticker'] = 'bcs'\n",
    "data = bcs\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data=data.sort_values(by=\"Date\",ascending=True)\n",
    "data.set_index(\"Date\",inplace=True)\n",
    "start_date = data.index.min()\n",
    "end_date = data.index.max()\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "missing_dates = all_dates.difference(data.index)\n",
    "print(\"The count of missing dates are: \",len(missing_dates))\n",
    "data = data.reindex(all_dates)\n",
    "data.ffill(inplace=True)\n",
    "data['Difference'] = data['Adj Close'].diff()\n",
    "data = data.dropna()\n",
    "data['Invest'] = 'No'\n",
    "data.loc[data['Difference'] >= 0, 'Invest'] = 'Yes'\n",
    "bcs = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of missing dates are:  908\n"
     ]
    }
   ],
   "source": [
    "cvx = pd.read_csv('CVX.csv')\n",
    "cvx['Ticker'] = 'cvx'\n",
    "data = cvx\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data=data.sort_values(by=\"Date\",ascending=True)\n",
    "data.set_index(\"Date\",inplace=True)\n",
    "start_date = data.index.min()\n",
    "end_date = data.index.max()\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "missing_dates = all_dates.difference(data.index)\n",
    "print(\"The count of missing dates are: \",len(missing_dates))\n",
    "data = data.reindex(all_dates)\n",
    "data.ffill(inplace=True)\n",
    "data['Difference'] = data['Adj Close'].diff()\n",
    "data = data.dropna()\n",
    "data['Invest'] = 'No'\n",
    "data.loc[data['Difference'] >= 0, 'Invest'] = 'Yes'\n",
    "cvx = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of missing dates are:  1011\n"
     ]
    }
   ],
   "source": [
    "googl = pd.read_csv('GOOGL.csv')\n",
    "googl['Ticker'] = 'googl'\n",
    "data = googl\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data=data.sort_values(by=\"Date\",ascending=True)\n",
    "data.set_index(\"Date\",inplace=True)\n",
    "start_date = data.index.min()\n",
    "end_date = data.index.max()\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "missing_dates = all_dates.difference(data.index)\n",
    "print(\"The count of missing dates are: \",len(missing_dates))\n",
    "data = data.reindex(all_dates)\n",
    "data.ffill(inplace=True)\n",
    "data['Difference'] = data['Adj Close'].diff()\n",
    "data = data.dropna()\n",
    "data['Invest'] = 'No'\n",
    "data.loc[data['Difference'] >= 0, 'Invest'] = 'Yes'\n",
    "googl = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of missing dates are:  112\n"
     ]
    }
   ],
   "source": [
    "htz = pd.read_csv('HTZ.csv')\n",
    "htz['Ticker'] = 'htz'\n",
    "data = htz\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data=data.sort_values(by=\"Date\",ascending=True)\n",
    "data.set_index(\"Date\",inplace=True)\n",
    "start_date = data.index.min()\n",
    "end_date = data.index.max()\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "missing_dates = all_dates.difference(data.index)\n",
    "print(\"The count of missing dates are: \",len(missing_dates))\n",
    "data = data.reindex(all_dates)\n",
    "data.ffill(inplace=True)\n",
    "data['Difference'] = data['Adj Close'].diff()\n",
    "data = data.dropna()\n",
    "data['Invest'] = 'No'\n",
    "data.loc[data['Difference'] >= 0, 'Invest'] = 'Yes'\n",
    "htz = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of missing dates are:  112\n"
     ]
    }
   ],
   "source": [
    "tm = pd.read_csv('TM.csv')\n",
    "tm['Ticker'] = 'tm'\n",
    "data = tm\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data=data.sort_values(by=\"Date\",ascending=True)\n",
    "data.set_index(\"Date\",inplace=True)\n",
    "start_date = data.index.min()\n",
    "end_date = data.index.max()\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "missing_dates = all_dates.difference(data.index)\n",
    "print(\"The count of missing dates are: \",len(missing_dates))\n",
    "data = data.reindex(all_dates)\n",
    "data.ffill(inplace=True)\n",
    "data['Difference'] = data['Adj Close'].diff()\n",
    "data = data.dropna()\n",
    "data['Invest'] = 'No'\n",
    "data.loc[data['Difference'] >= 0, 'Invest'] = 'Yes'\n",
    "tm = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of missing dates are:  908\n"
     ]
    }
   ],
   "source": [
    "wmt = pd.read_csv('WMT.csv')\n",
    "wmt['Ticker'] = 'wmt'\n",
    "data = wmt\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data=data.sort_values(by=\"Date\",ascending=True)\n",
    "data.set_index(\"Date\",inplace=True)\n",
    "start_date = data.index.min()\n",
    "end_date = data.index.max()\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "missing_dates = all_dates.difference(data.index)\n",
    "print(\"The count of missing dates are: \",len(missing_dates))\n",
    "data = data.reindex(all_dates)\n",
    "data['Difference'] = data['Adj Close'].diff()\n",
    "data.ffill(inplace=True)\n",
    "data = data.dropna()\n",
    "data['Invest'] = 'No'\n",
    "data.loc[data['Difference'] >= 0, 'Invest'] = 'Yes'\n",
    "wmt = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance = pd.concat([amzn,bcs,cvx,googl,htz,tm,wmt],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance['date'] = pd.to_datetime(finance.index)\n",
    "finance = finance.reset_index(drop=True)\n",
    "finance.index = finance.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Title'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = df.groupby(['Ticker', 'date'])[['postive','negative','neutral','compound']].mean().reset_index()\n",
    "avg_df['date'] = pd.to_datetime(avg_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final =  pd.merge(avg_df, finance, on=['date','Ticker'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>postive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>compound</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Invest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amzn</td>\n",
       "      <td>2023-11-29</td>\n",
       "      <td>0.196462</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>0.771308</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>147.850006</td>\n",
       "      <td>148.539993</td>\n",
       "      <td>145.970001</td>\n",
       "      <td>146.320007</td>\n",
       "      <td>146.320007</td>\n",
       "      <td>40610900.0</td>\n",
       "      <td>-0.709992</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amzn</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>0.161952</td>\n",
       "      <td>0.037286</td>\n",
       "      <td>0.800762</td>\n",
       "      <td>0.166767</td>\n",
       "      <td>144.759995</td>\n",
       "      <td>146.929993</td>\n",
       "      <td>144.330002</td>\n",
       "      <td>146.089996</td>\n",
       "      <td>146.089996</td>\n",
       "      <td>65814000.0</td>\n",
       "      <td>-0.230011</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bcs</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>-0.226300</td>\n",
       "      <td>7.770000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>7.590000</td>\n",
       "      <td>7.590000</td>\n",
       "      <td>9308300.0</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bcs</td>\n",
       "      <td>2023-10-04</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.079667</td>\n",
       "      <td>0.843667</td>\n",
       "      <td>-0.008600</td>\n",
       "      <td>7.550000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>7.480000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>7859600.0</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bcs</td>\n",
       "      <td>2023-10-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.783000</td>\n",
       "      <td>-0.361200</td>\n",
       "      <td>7.460000</td>\n",
       "      <td>7.540000</td>\n",
       "      <td>7.450000</td>\n",
       "      <td>7.530000</td>\n",
       "      <td>7.530000</td>\n",
       "      <td>8171000.0</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>wmt</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.505100</td>\n",
       "      <td>155.149994</td>\n",
       "      <td>156.130005</td>\n",
       "      <td>154.699997</td>\n",
       "      <td>156.059998</td>\n",
       "      <td>156.059998</td>\n",
       "      <td>4658400.0</td>\n",
       "      <td>-1.190003</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>wmt</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>0.075429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.924571</td>\n",
       "      <td>0.100657</td>\n",
       "      <td>155.949997</td>\n",
       "      <td>157.360001</td>\n",
       "      <td>155.949997</td>\n",
       "      <td>156.770004</td>\n",
       "      <td>156.770004</td>\n",
       "      <td>7797900.0</td>\n",
       "      <td>-1.190003</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>wmt</td>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.811000</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>156.660004</td>\n",
       "      <td>158.919998</td>\n",
       "      <td>156.660004</td>\n",
       "      <td>158.639999</td>\n",
       "      <td>158.639999</td>\n",
       "      <td>7845000.0</td>\n",
       "      <td>1.869995</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>wmt</td>\n",
       "      <td>2023-11-29</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.772250</td>\n",
       "      <td>0.011225</td>\n",
       "      <td>158.770004</td>\n",
       "      <td>158.770004</td>\n",
       "      <td>155.610001</td>\n",
       "      <td>156.080002</td>\n",
       "      <td>156.080002</td>\n",
       "      <td>9965500.0</td>\n",
       "      <td>-2.559997</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>wmt</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>0.196778</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.783889</td>\n",
       "      <td>0.323078</td>\n",
       "      <td>156.020004</td>\n",
       "      <td>156.350006</td>\n",
       "      <td>154.509995</td>\n",
       "      <td>155.690002</td>\n",
       "      <td>155.690002</td>\n",
       "      <td>9975300.0</td>\n",
       "      <td>-0.390000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker       date   postive  negative   neutral  compound        Open  \\\n",
       "0     amzn 2023-11-29  0.196462  0.032231  0.771308  0.240346  147.850006   \n",
       "1     amzn 2023-11-30  0.161952  0.037286  0.800762  0.166767  144.759995   \n",
       "2      bcs 2023-10-02  0.000000  0.174000  0.826000 -0.226300    7.770000   \n",
       "3      bcs 2023-10-04  0.076667  0.079667  0.843667 -0.008600    7.550000   \n",
       "4      bcs 2023-10-05  0.000000  0.217000  0.783000 -0.361200    7.460000   \n",
       "..     ...        ...       ...       ...       ...       ...         ...   \n",
       "157    wmt 2023-11-25  0.295000  0.000000  0.705000  0.505100  155.149994   \n",
       "158    wmt 2023-11-27  0.075429  0.000000  0.924571  0.100657  155.949997   \n",
       "159    wmt 2023-11-28  0.112000  0.077000  0.811000  0.058617  156.660004   \n",
       "160    wmt 2023-11-29  0.093750  0.134000  0.772250  0.011225  158.770004   \n",
       "161    wmt 2023-11-30  0.196778  0.019333  0.783889  0.323078  156.020004   \n",
       "\n",
       "           High         Low       Close   Adj Close      Volume  Difference  \\\n",
       "0    148.539993  145.970001  146.320007  146.320007  40610900.0   -0.709992   \n",
       "1    146.929993  144.330002  146.089996  146.089996  65814000.0   -0.230011   \n",
       "2      7.800000    7.570000    7.590000    7.590000   9308300.0   -0.200000   \n",
       "3      7.570000    7.480000    7.570000    7.570000   7859600.0    0.070000   \n",
       "4      7.540000    7.450000    7.530000    7.530000   8171000.0   -0.040000   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "157  156.130005  154.699997  156.059998  156.059998   4658400.0   -1.190003   \n",
       "158  157.360001  155.949997  156.770004  156.770004   7797900.0   -1.190003   \n",
       "159  158.919998  156.660004  158.639999  158.639999   7845000.0    1.869995   \n",
       "160  158.770004  155.610001  156.080002  156.080002   9965500.0   -2.559997   \n",
       "161  156.350006  154.509995  155.690002  155.690002   9975300.0   -0.390000   \n",
       "\n",
       "    Invest  \n",
       "0       No  \n",
       "1       No  \n",
       "2       No  \n",
       "3      Yes  \n",
       "4       No  \n",
       "..     ...  \n",
       "157     No  \n",
       "158     No  \n",
       "159    Yes  \n",
       "160     No  \n",
       "161     No  \n",
       "\n",
       "[162 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 23:20:33.257870: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nn_data_creation(data):\n",
    "#     adj_values = data[['Adj Close']].values\n",
    "#     needed = int(len(adj_values)*0.8)\n",
    "#     train = adj_values[0:needed, :]\n",
    "#     scaler = MinMaxScaler(feature_range=(0,1))\n",
    "#     train_scaled = scaler.fit_transform(train)\n",
    "#     X_train = []\n",
    "#     y_train = []\n",
    "#     for i in range(7, len(train)):\n",
    "#         X_train.append(train_scaled[i-7:i, 0])\n",
    "#         y_train.append(train_scaled[i:i+7, 0]) \n",
    "#     X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "#     X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "#     y_train = np.reshape(y_train, (y_train.shape[0],1))\n",
    "    \n",
    "#     test = data[['Adj Close']][needed:].values\n",
    "#     #inputs = data[['Adj Close']][len(adj_values) - len(test) - 7:].values\n",
    "#     test = np.reshape(test,(-1,1))\n",
    "#     test  = scaler.transform(test)\n",
    "    \n",
    "#     X_test = []\n",
    "#     y_test = []\n",
    "#     for i in range(7,len(data)-needed):\n",
    "#         X_test.append(test[i-7:i,0])\n",
    "#         y_test.append(test[i:i+7,0])\n",
    "#     X_test = np.array(X_test)\n",
    "#     y_test = np.array(y_test)\n",
    "#     X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "#     y_test = np.reshape(y_test, (y_test.shape[0],1))\n",
    "#     return X_train,y_train,X_test,y_test,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_data_creation(data):\n",
    "    adj_values = data[['Adj Close']].values\n",
    "    needed = int(len(adj_values) * 0.8)\n",
    "    \n",
    "    train = adj_values[0:needed, :]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_scaled = scaler.fit_transform(train)\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    for i in range(7, len(train)-7):\n",
    "        X_train.append(train_scaled[i-7:i, 0])\n",
    "        y_train.append(train_scaled[i:i+7, 0]) \n",
    "        \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], 7, 1))  # Corrected to match the model output\n",
    "    \n",
    "    test = data[['Adj Close']][needed:].values\n",
    "    test = np.reshape(test, (-1, 1))\n",
    "    test = scaler.transform(test)\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for i in range(7, len(data) - needed-7):\n",
    "        X_test.append(test[i-7:i, 0])\n",
    "        y_test.append(test[i:i+7, 0])\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0], 7, 1))  # Corrected to match the model output\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "def rnn_model(X_train,y_train):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(32, return_sequences=True, input_shape=(X_train.shape[1],1)))  \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(SimpleRNN(32, return_sequences=True)) \n",
    "    model.add(Dropout(0.2)) \n",
    "    model.add(SimpleRNN(32))\n",
    "    model.add(Dense(7))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=64, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(amzn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(amzn)\n",
    "amzn_model_1 = rnn_model(X_train,y_train)\n",
    "predictions = amzn_model_1.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = np.reshape(y_test,(y_test.shape[0],y_test.shape[1]))\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.319\n",
      "R^2 score: 0.276\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(bcs)\n",
    "bcs_model_1 = rnn_model(X_train,y_train)\n",
    "predictions = bcs_model_1.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = np.reshape(y_test,(y_test.shape[0],y_test.shape[1]))\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6.439\n",
      "R^2 score: -0.433\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(cvx)\n",
    "cvx_model_1 = rnn_model(X_train,y_train)\n",
    "predictions = cvx_model_1.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = np.reshape(y_test,(y_test.shape[0],y_test.shape[1]))\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.916\n",
      "R^2 score: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(googl)\n",
    "googl_model_1 = rnn_model(X_train,y_train)\n",
    "predictions = googl_model_1.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = np.reshape(y_test,(y_test.shape[0],y_test.shape[1]))\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.429\n",
      "R^2 score: -3.702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(htz)\n",
    "htz_model_1 = rnn_model(X_train,y_train)\n",
    "predictions = htz_model_1.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = np.reshape(y_test,(y_test.shape[0],y_test.shape[1]))\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6.88\n",
      "R^2 score: -2.604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(tm)\n",
    "tm_model_1 = rnn_model(X_train,y_train)\n",
    "predictions = tm_model_1.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = np.reshape(y_test,(y_test.shape[0],y_test.shape[1]))\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.045\n",
      "R^2 score: 0.724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(wmt)\n",
    "wmt_model_1 = rnn_model(X_train,y_train)\n",
    "predictions = wmt_model_1.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = np.reshape(y_test,(y_test.shape[0],y_test.shape[1]))\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.175\n",
      "R^2 score: 0.967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(amzn)\n",
    "amzn_model = rnn_model(X_train,y_train)\n",
    "predictions = amzn_model.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.207\n",
      "R^2 score: 0.788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(bcs)\n",
    "bcs_model = rnn_model(X_train,y_train)\n",
    "predictions = bcs_model.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.563\n",
      "R^2 score: 0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(cvx)\n",
    "cvx_model = rnn_model(X_train,y_train)\n",
    "predictions = cvx_model.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.41\n",
      "R^2 score: 0.977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(googl)\n",
    "googl_model = rnn_model(X_train,y_train)\n",
    "predictions = googl_model.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.88\n",
      "R^2 score: 0.228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(htz)\n",
    "htz_model = rnn_model(X_train,y_train)\n",
    "predictions = htz_model.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.925\n",
      "R^2 score: 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(tm)\n",
    "tm_model = rnn_model(X_train,y_train)\n",
    "predictions = tm_model.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.594\n",
      "R^2 score: 0.701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train,y_train,X_test,y_test,scaler = nn_data_creation(wmt)\n",
    "wmt_model = rnn_model(X_train,y_train)\n",
    "predictions = wmt_model.predict(X_test,verbose=0)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "print('RMSE: {}'.format(round(mean_squared_error(predictions ,y_test, squared=False), 3)))\n",
    "print('R^2 score: {}'.format(round(r2_score(predictions, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_name(tic):\n",
    "    if tic=='amzn':\n",
    "        model = amzn_model_1\n",
    "        data = amzn\n",
    "    elif tic =='bcs':\n",
    "        model = bcs_model_1\n",
    "        data = bcs\n",
    "    elif tic == 'cvx':\n",
    "        model = cvx_model_1\n",
    "        data = cvx\n",
    "    elif tic == 'googl':\n",
    "        model = googl_model_1\n",
    "        data = googl\n",
    "    elif tic == 'htz':\n",
    "        model = htz_model_1\n",
    "        data = htz\n",
    "    elif tic == 'tm':\n",
    "        model = tm_model_1\n",
    "        data = tm\n",
    "    else:\n",
    "        model = wmt_model_1\n",
    "        data = wmt\n",
    "    return model,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "def next_seven(tic,date):\n",
    "    model,data = model_name(tic)\n",
    "    check_date = pd.to_datetime(date)\n",
    "    past_val = []\n",
    "    for i in range(7):\n",
    "        temp = check_date - timedelta(days=i)\n",
    "        if pd.to_datetime(temp) in data.index:\n",
    "            val = data.loc[pd.to_datetime(temp), 'Adj Close']\n",
    "            past_val.append(val)\n",
    "        else:\n",
    "            pass\n",
    "    if len(past_val) == 7:\n",
    "        past_val_arr = np.reshape(np.array(past_val),(-1,1))\n",
    "        past_val_reshaped = past_val_arr.reshape(1,-1,1)\n",
    "        t = model.predict(past_val_reshaped,verbose=0) \n",
    "        f = scaler.inverse_transform(t)\n",
    "        return f\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime, timedelta\n",
    "# def next_seven(tic,date):\n",
    "#     model,data = model_name(tic)\n",
    "#     f1 = []\n",
    "#     for j in range(7):\n",
    "#         check_date = pd.to_datetime(date)\n",
    "#         past_val = f1.copy()\n",
    "#         for i in range(7-j):\n",
    "#             temp = check_date - timedelta(days=i+10+j)\n",
    "#             if pd.to_datetime(temp) in data.index:\n",
    "#                 val = data.loc[pd.to_datetime(temp), 'Adj Close']\n",
    "#                 past_val.append(val)\n",
    "#             else:\n",
    "#                 # Handle missing data (e.g., use a default value or skip)\n",
    "#                 pass\n",
    "#             #val = data.loc[pd.to_datetime(temp),'Adj Close']\n",
    "#             #past_val.append(val)\n",
    "#         if len(past_val)==7:\n",
    "#             past_val = np.reshape(np.array(past_val),(-1,1))\n",
    "#             past_val = scaler.transform(past_val)\n",
    "#             past_val_reshaped = past_val.reshape(1, -1, 1)\n",
    "#             t = model.predict(past_val_reshaped,verbose=0) \n",
    "#             f = scaler.inverse_transform(t)\n",
    "#             f1.append(f[0][0])\n",
    "#         else:\n",
    "#             pass\n",
    "#     return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_f = finance\n",
    "new_f['result'] = new_f.apply(lambda row: next_seven(row['Ticker'], row['date'],), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashashvini/anaconda3/envs/python38/lib/python3.8/site-packages/pandas/core/missing.py:106: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  new_mask[arr_mask] = arr[arr_mask] == x\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Invest</th>\n",
       "      <th>date</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.156502</td>\n",
       "      <td>33.999500</td>\n",
       "      <td>32.989498</td>\n",
       "      <td>33.866501</td>\n",
       "      <td>33.866501</td>\n",
       "      <td>73038000.0</td>\n",
       "      <td>amzn</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>[[80.909454, 172.63925, 69.60054, 178.16803, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.900002</td>\n",
       "      <td>33.950001</td>\n",
       "      <td>32.784000</td>\n",
       "      <td>33.239498</td>\n",
       "      <td>33.239498</td>\n",
       "      <td>103164000.0</td>\n",
       "      <td>amzn</td>\n",
       "      <td>-0.627003</td>\n",
       "      <td>No</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>[[80.853905, 172.72963, 69.61179, 178.19397, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.279499</td>\n",
       "      <td>33.426498</td>\n",
       "      <td>32.978001</td>\n",
       "      <td>33.116001</td>\n",
       "      <td>33.116001</td>\n",
       "      <td>69110000.0</td>\n",
       "      <td>amzn</td>\n",
       "      <td>-0.123497</td>\n",
       "      <td>No</td>\n",
       "      <td>2015-12-10</td>\n",
       "      <td>[[80.88811, 172.6776, 69.6176, 178.17477, 234....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.561501</td>\n",
       "      <td>32.894001</td>\n",
       "      <td>31.981001</td>\n",
       "      <td>32.007500</td>\n",
       "      <td>32.007500</td>\n",
       "      <td>109488000.0</td>\n",
       "      <td>amzn</td>\n",
       "      <td>-1.108501</td>\n",
       "      <td>No</td>\n",
       "      <td>2015-12-11</td>\n",
       "      <td>[[80.88763, 172.67921, 69.61818, 178.17534, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.561501</td>\n",
       "      <td>32.894001</td>\n",
       "      <td>31.981001</td>\n",
       "      <td>32.007500</td>\n",
       "      <td>32.007500</td>\n",
       "      <td>109488000.0</td>\n",
       "      <td>amzn</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2015-12-12</td>\n",
       "      <td>[[80.88924, 172.6724, 69.61162, 178.17453, 234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13054</th>\n",
       "      <td>155.149994</td>\n",
       "      <td>156.130005</td>\n",
       "      <td>154.699997</td>\n",
       "      <td>156.059998</td>\n",
       "      <td>156.059998</td>\n",
       "      <td>4658400.0</td>\n",
       "      <td>wmt</td>\n",
       "      <td>-1.190003</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-11-26</td>\n",
       "      <td>[[168.90338, 204.81299, 154.91382, 218.90895, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13055</th>\n",
       "      <td>155.949997</td>\n",
       "      <td>157.360001</td>\n",
       "      <td>155.949997</td>\n",
       "      <td>156.770004</td>\n",
       "      <td>156.770004</td>\n",
       "      <td>7797900.0</td>\n",
       "      <td>wmt</td>\n",
       "      <td>-1.190003</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>[[168.89877, 204.81972, 154.91498, 218.91777, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13056</th>\n",
       "      <td>156.660004</td>\n",
       "      <td>158.919998</td>\n",
       "      <td>156.660004</td>\n",
       "      <td>158.639999</td>\n",
       "      <td>158.639999</td>\n",
       "      <td>7845000.0</td>\n",
       "      <td>wmt</td>\n",
       "      <td>1.869995</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>[[168.89474, 204.80936, 154.88419, 218.88518, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13057</th>\n",
       "      <td>158.770004</td>\n",
       "      <td>158.770004</td>\n",
       "      <td>155.610001</td>\n",
       "      <td>156.080002</td>\n",
       "      <td>156.080002</td>\n",
       "      <td>9965500.0</td>\n",
       "      <td>wmt</td>\n",
       "      <td>-2.559997</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-11-29</td>\n",
       "      <td>[[168.90019, 204.80511, 154.89317, 218.88974, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13058</th>\n",
       "      <td>156.020004</td>\n",
       "      <td>156.350006</td>\n",
       "      <td>154.509995</td>\n",
       "      <td>155.690002</td>\n",
       "      <td>155.690002</td>\n",
       "      <td>9975300.0</td>\n",
       "      <td>wmt</td>\n",
       "      <td>-0.390000</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>[[168.9025, 204.81303, 154.91919, 218.92122, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13059 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open        High         Low       Close   Adj Close  \\\n",
       "0       33.156502   33.999500   32.989498   33.866501   33.866501   \n",
       "1       33.900002   33.950001   32.784000   33.239498   33.239498   \n",
       "2       33.279499   33.426498   32.978001   33.116001   33.116001   \n",
       "3       32.561501   32.894001   31.981001   32.007500   32.007500   \n",
       "4       32.561501   32.894001   31.981001   32.007500   32.007500   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "13054  155.149994  156.130005  154.699997  156.059998  156.059998   \n",
       "13055  155.949997  157.360001  155.949997  156.770004  156.770004   \n",
       "13056  156.660004  158.919998  156.660004  158.639999  158.639999   \n",
       "13057  158.770004  158.770004  155.610001  156.080002  156.080002   \n",
       "13058  156.020004  156.350006  154.509995  155.690002  155.690002   \n",
       "\n",
       "            Volume Ticker  Difference Invest       date  \\\n",
       "0       73038000.0   amzn    0.375000    Yes 2015-12-08   \n",
       "1      103164000.0   amzn   -0.627003     No 2015-12-09   \n",
       "2       69110000.0   amzn   -0.123497     No 2015-12-10   \n",
       "3      109488000.0   amzn   -1.108501     No 2015-12-11   \n",
       "4      109488000.0   amzn    0.000000    Yes 2015-12-12   \n",
       "...            ...    ...         ...    ...        ...   \n",
       "13054    4658400.0    wmt   -1.190003     No 2023-11-26   \n",
       "13055    7797900.0    wmt   -1.190003     No 2023-11-27   \n",
       "13056    7845000.0    wmt    1.869995    Yes 2023-11-28   \n",
       "13057    9965500.0    wmt   -2.559997     No 2023-11-29   \n",
       "13058    9975300.0    wmt   -0.390000     No 2023-11-30   \n",
       "\n",
       "                                                  result  \n",
       "0      [[80.909454, 172.63925, 69.60054, 178.16803, 2...  \n",
       "1      [[80.853905, 172.72963, 69.61179, 178.19397, 2...  \n",
       "2      [[80.88811, 172.6776, 69.6176, 178.17477, 234....  \n",
       "3      [[80.88763, 172.67921, 69.61818, 178.17534, 23...  \n",
       "4      [[80.88924, 172.6724, 69.61162, 178.17453, 234...  \n",
       "...                                                  ...  \n",
       "13054  [[168.90338, 204.81299, 154.91382, 218.90895, ...  \n",
       "13055  [[168.89877, 204.81972, 154.91498, 218.91777, ...  \n",
       "13056  [[168.89474, 204.80936, 154.88419, 218.88518, ...  \n",
       "13057  [[168.90019, 204.80511, 154.89317, 218.88974, ...  \n",
       "13058  [[168.9025, 204.81303, 154.91919, 218.92122, 1...  \n",
       "\n",
       "[13059 rows x 11 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_f = new_f.replace(to_replace='None', value=np.nan).dropna()\n",
    "new_f = new_f.reset_index()\n",
    "new_f = new_f.drop(['index'],axis=1)\n",
    "new_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_next_seven(data):\n",
    "    temp = pd.DataFrame(data,columns=['next_1','next_2','next_3','next_4','next_5','next_6','next_7'])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawback, only works from 2015, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Invest</th>\n",
       "      <th>date</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.156502</td>\n",
       "      <td>33.999500</td>\n",
       "      <td>32.989498</td>\n",
       "      <td>33.866501</td>\n",
       "      <td>33.866501</td>\n",
       "      <td>73038000.0</td>\n",
       "      <td>amzn</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>[[80.909454, 172.63925, 69.60054, 178.16803, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.900002</td>\n",
       "      <td>33.950001</td>\n",
       "      <td>32.784000</td>\n",
       "      <td>33.239498</td>\n",
       "      <td>33.239498</td>\n",
       "      <td>103164000.0</td>\n",
       "      <td>amzn</td>\n",
       "      <td>-0.627003</td>\n",
       "      <td>No</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>[[80.853905, 172.72963, 69.61179, 178.19397, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.279499</td>\n",
       "      <td>33.426498</td>\n",
       "      <td>32.978001</td>\n",
       "      <td>33.116001</td>\n",
       "      <td>33.116001</td>\n",
       "      <td>69110000.0</td>\n",
       "      <td>amzn</td>\n",
       "      <td>-0.123497</td>\n",
       "      <td>No</td>\n",
       "      <td>2015-12-10</td>\n",
       "      <td>[[80.88811, 172.6776, 69.6176, 178.17477, 234....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.561501</td>\n",
       "      <td>32.894001</td>\n",
       "      <td>31.981001</td>\n",
       "      <td>32.007500</td>\n",
       "      <td>32.007500</td>\n",
       "      <td>109488000.0</td>\n",
       "      <td>amzn</td>\n",
       "      <td>-1.108501</td>\n",
       "      <td>No</td>\n",
       "      <td>2015-12-11</td>\n",
       "      <td>[[80.88763, 172.67921, 69.61818, 178.17534, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.561501</td>\n",
       "      <td>32.894001</td>\n",
       "      <td>31.981001</td>\n",
       "      <td>32.007500</td>\n",
       "      <td>32.007500</td>\n",
       "      <td>109488000.0</td>\n",
       "      <td>amzn</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2015-12-12</td>\n",
       "      <td>[[80.88924, 172.6724, 69.61162, 178.17453, 234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13054</th>\n",
       "      <td>155.149994</td>\n",
       "      <td>156.130005</td>\n",
       "      <td>154.699997</td>\n",
       "      <td>156.059998</td>\n",
       "      <td>156.059998</td>\n",
       "      <td>4658400.0</td>\n",
       "      <td>wmt</td>\n",
       "      <td>-1.190003</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-11-26</td>\n",
       "      <td>[[168.90338, 204.81299, 154.91382, 218.90895, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13055</th>\n",
       "      <td>155.949997</td>\n",
       "      <td>157.360001</td>\n",
       "      <td>155.949997</td>\n",
       "      <td>156.770004</td>\n",
       "      <td>156.770004</td>\n",
       "      <td>7797900.0</td>\n",
       "      <td>wmt</td>\n",
       "      <td>-1.190003</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>[[168.89877, 204.81972, 154.91498, 218.91777, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13056</th>\n",
       "      <td>156.660004</td>\n",
       "      <td>158.919998</td>\n",
       "      <td>156.660004</td>\n",
       "      <td>158.639999</td>\n",
       "      <td>158.639999</td>\n",
       "      <td>7845000.0</td>\n",
       "      <td>wmt</td>\n",
       "      <td>1.869995</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>[[168.89474, 204.80936, 154.88419, 218.88518, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13057</th>\n",
       "      <td>158.770004</td>\n",
       "      <td>158.770004</td>\n",
       "      <td>155.610001</td>\n",
       "      <td>156.080002</td>\n",
       "      <td>156.080002</td>\n",
       "      <td>9965500.0</td>\n",
       "      <td>wmt</td>\n",
       "      <td>-2.559997</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-11-29</td>\n",
       "      <td>[[168.90019, 204.80511, 154.89317, 218.88974, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13058</th>\n",
       "      <td>156.020004</td>\n",
       "      <td>156.350006</td>\n",
       "      <td>154.509995</td>\n",
       "      <td>155.690002</td>\n",
       "      <td>155.690002</td>\n",
       "      <td>9975300.0</td>\n",
       "      <td>wmt</td>\n",
       "      <td>-0.390000</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>[[168.9025, 204.81303, 154.91919, 218.92122, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13059 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open        High         Low       Close   Adj Close  \\\n",
       "0       33.156502   33.999500   32.989498   33.866501   33.866501   \n",
       "1       33.900002   33.950001   32.784000   33.239498   33.239498   \n",
       "2       33.279499   33.426498   32.978001   33.116001   33.116001   \n",
       "3       32.561501   32.894001   31.981001   32.007500   32.007500   \n",
       "4       32.561501   32.894001   31.981001   32.007500   32.007500   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "13054  155.149994  156.130005  154.699997  156.059998  156.059998   \n",
       "13055  155.949997  157.360001  155.949997  156.770004  156.770004   \n",
       "13056  156.660004  158.919998  156.660004  158.639999  158.639999   \n",
       "13057  158.770004  158.770004  155.610001  156.080002  156.080002   \n",
       "13058  156.020004  156.350006  154.509995  155.690002  155.690002   \n",
       "\n",
       "            Volume Ticker  Difference Invest       date  \\\n",
       "0       73038000.0   amzn    0.375000    Yes 2015-12-08   \n",
       "1      103164000.0   amzn   -0.627003     No 2015-12-09   \n",
       "2       69110000.0   amzn   -0.123497     No 2015-12-10   \n",
       "3      109488000.0   amzn   -1.108501     No 2015-12-11   \n",
       "4      109488000.0   amzn    0.000000    Yes 2015-12-12   \n",
       "...            ...    ...         ...    ...        ...   \n",
       "13054    4658400.0    wmt   -1.190003     No 2023-11-26   \n",
       "13055    7797900.0    wmt   -1.190003     No 2023-11-27   \n",
       "13056    7845000.0    wmt    1.869995    Yes 2023-11-28   \n",
       "13057    9965500.0    wmt   -2.559997     No 2023-11-29   \n",
       "13058    9975300.0    wmt   -0.390000     No 2023-11-30   \n",
       "\n",
       "                                                  result  \n",
       "0      [[80.909454, 172.63925, 69.60054, 178.16803, 2...  \n",
       "1      [[80.853905, 172.72963, 69.61179, 178.19397, 2...  \n",
       "2      [[80.88811, 172.6776, 69.6176, 178.17477, 234....  \n",
       "3      [[80.88763, 172.67921, 69.61818, 178.17534, 23...  \n",
       "4      [[80.88924, 172.6724, 69.61162, 178.17453, 234...  \n",
       "...                                                  ...  \n",
       "13054  [[168.90338, 204.81299, 154.91382, 218.90895, ...  \n",
       "13055  [[168.89877, 204.81972, 154.91498, 218.91777, ...  \n",
       "13056  [[168.89474, 204.80936, 154.88419, 218.88518, ...  \n",
       "13057  [[168.90019, 204.80511, 154.89317, 218.88974, ...  \n",
       "13058  [[168.9025, 204.81303, 154.91919, 218.92122, 1...  \n",
       "\n",
       "[13059 rows x 11 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_f.to_csv('next_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(new_f['result'])\n",
    "temp[['next_1','next_2','next_3','next_4','next_5','next_6','next_7']] = temp['result'].apply(lambda x: pd.Series(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_new = pd.concat([temp,new_f],axis=1)\n",
    "f_new = f_new.drop(['result'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_new = f_new.drop(['Open','Close','High','Low','Close','Volume','Adj Close'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_senti = f_new.drop(['Difference'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = pd.merge(final,no_senti,on=['Ticker','date','Invest'])\n",
    "senti = senti.dropna()\n",
    "senti = senti.drop(['Open','High', 'Low', 'Close', 'Adj Close', 'Volume', 'Difference'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "no_senti['Ticker']= le.fit_transform(no_senti['Ticker'])\n",
    "senti['Ticker']= le.transform(senti['Ticker'])\n",
    "no_senti = no_senti.drop(['date'],axis=1)\n",
    "senti = senti.drop(['date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "no_senti['Invest']= le.fit_transform(no_senti['Invest'])\n",
    "senti['Invest']= le.transform(senti['Invest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_senti = no_senti.drop(['Ticker'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = senti.drop(['Ticker'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_senti,X_test_no_senti,y_train_no_senti,y_test_no_senti = train_test_split(no_senti.drop(['Invest'],axis=1).values,no_senti['Invest'].values,test_size=0.3,random_state=42)\n",
    "X_train_senti,X_test_senti,y_train_senti,y_test_senti = train_test_split(senti.drop(['Invest'],axis=1).values,senti['Invest'].values,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_no_senti = scaler.fit_transform(X_train_no_senti)\n",
    "X_test_no_senti = scaler.transform(X_test_no_senti)\n",
    "X_train_senti = scaler.fit_transform(X_train_senti)\n",
    "X_test_senti = scaler.transform(X_test_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model_no_senti = LogisticRegression()\n",
    "\n",
    "model_no_senti.fit(X_train_no_senti,y_train_no_senti)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.630423685553854\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_no_senti.predict(X_test_no_senti)\n",
    "accuracy = accuracy_score(y_test_no_senti, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model_senti = LogisticRegression()\n",
    "model_senti.fit(X_train_senti,y_train_senti)\n",
    "y_pred = model_senti.predict(X_test_senti)\n",
    "accuracy = accuracy_score(y_test_senti, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "def next_seven(tic,date):\n",
    "    model,data = model_name(tic)\n",
    "    check_date = pd.to_datetime(date)\n",
    "    past_val = []\n",
    "    for i in range(7):\n",
    "        temp = check_date - timedelta(days=i)\n",
    "        if pd.to_datetime(temp) in data.index:\n",
    "            val = data.loc[pd.to_datetime(temp), 'Adj Close']\n",
    "            past_val.append(val)\n",
    "        else:\n",
    "            pass\n",
    "    if len(past_val) == 7:\n",
    "        past_val_arr = np.reshape(np.array(past_val),(-1,1))\n",
    "        past_val_reshaped = past_val_arr.reshape(1,-1,1)\n",
    "        t = model.predict(past_val_reshaped,verbose=0) \n",
    "        f = scaler.inverse_transform(t)\n",
    "        return f\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can\n"
     ]
    }
   ],
   "source": [
    "user_input = input('Enter the date and Stock Name [AMZN,BCS,CVX,GOOGL,HTZ,TM,WMT]')\n",
    "date,tick = user_input.split(',')[0],user_input.split(',')[1]\n",
    "next_seven_days = next_seven(tick,date)\n",
    "l = final[(final['Ticker'] == tick) & (final['date'] == date)].index.to_list()\n",
    "if len(l)>0:\n",
    "        id = l[0]\n",
    "        next_seven_days= np.insert(next_seven_days,0,final.iloc[id]['postive'])\n",
    "        next_seven_days= np.insert(next_seven_days,1,final.iloc[id]['negative'])\n",
    "        next_seven_days= np.insert(next_seven_days,2,final.iloc[id]['neutral'])\n",
    "        next_seven_days =np.insert(next_seven_days,3,final.iloc[id]['compound'])\n",
    "        next_seven_days = next_seven_days.reshape(1,-1)\n",
    "        predict = model_senti.predict(next_seven_days)\n",
    "else:\n",
    "    next_seven_days = next_seven_days.reshape(1,-1)\n",
    "    predict = model_no_senti.predict(next_seven_days)\n",
    "\n",
    "if predict == 1:\n",
    "      print('You can')\n",
    "else:\n",
    "      print('You Cannot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
